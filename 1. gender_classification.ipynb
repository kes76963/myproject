{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "import re\r\n",
    "import numpy as np\r\n",
    "from tensorflow.keras.utils import to_categorical\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.preprocessing import LabelEncoder\r\n",
    "from tensorflow.keras.preprocessing.text import *\r\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n",
    "import pickle\r\n",
    "from konlpy.tag import Okt, Kkma, Mecab\r\n",
    "\r\n",
    "pd.set_option('display.unicode.east_asian_width',True)\r\n",
    "\r\n",
    "#중복 확인\r\n",
    "df = pd.read_csv('./name_gender.csv')\r\n",
    "col_dup = df['name'].duplicated()\r\n",
    "print(col_dup)\r\n",
    "sum_dup = df['name'].duplicated().sum()\r\n",
    "print(sum_dup)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\kim\\.conda\\envs\\exam_cv2\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\kim\\.conda\\envs\\exam_cv2\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "C:\\Users\\kim\\.conda\\envs\\exam_cv2\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "C:\\Users\\kim\\.conda\\envs\\exam_cv2\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0        False\n",
      "1        False\n",
      "2        False\n",
      "3        False\n",
      "4        False\n",
      "         ...  \n",
      "59899    False\n",
      "59900    False\n",
      "59901    False\n",
      "59902    False\n",
      "59903    False\n",
      "Name: name, Length: 59904, dtype: bool\n",
      "0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "df = df.drop_duplicates(subset=['name'])\r\n",
    "sum_dup = df['name'].duplicated().sum()\r\n",
    "print(sum_dup)\r\n",
    "\r\n",
    "df.reset_index(drop=True, inplace=True)\r\n",
    "\r\n",
    "X = df['name']\r\n",
    "Y = df['gender']\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#라벨인코딩\r\n",
    "encoder = LabelEncoder()\r\n",
    "labeled_Y = encoder.fit_transform(Y)\r\n",
    "label = encoder.classes_\r\n",
    "print(label)\r\n",
    "\r\n",
    "#피클로 저장\r\n",
    "with open('./model/gender_encoder.pickle', 'wb') as f:\r\n",
    "    pickle.dump(encoder, f)\r\n",
    "\r\n",
    "print(labeled_Y)\r\n",
    "\r\n",
    "onehot_Y = to_categorical(labeled_Y)\r\n",
    "print(onehot_Y)\r\n",
    "\r\n",
    "################ okt 70초\r\n",
    "# okt = Okt()\r\n",
    "# print(type(X))\r\n",
    "# okt_X = okt.morphs(X[0])\r\n",
    "# print(X[0])\r\n",
    "# print(okt_X)\r\n",
    "\r\n",
    "\r\n",
    "# for i in range(len(X)):\r\n",
    "#     X[i] = okt.morphs(X[i])\r\n",
    "# print(X)\r\n",
    "\r\n",
    "\r\n",
    "############### 꼬마 200초 이상\r\n",
    "# kkma = Kkma()\r\n",
    "# print(type(X))\r\n",
    "# kkma_X = kkma.morphs(X[0])\r\n",
    "# print(X[0])\r\n",
    "# print(kkma_X)\r\n",
    "\r\n",
    "# for i in range(len(X)):\r\n",
    "#   X[i] = kkma.morphs(X[i])\r\n",
    "# print(X)\r\n",
    "\r\n",
    "############### 메캅 40초\r\n",
    "mecab=Mecab(dicpath='C:/mecab/mecab-ko-dic')\r\n",
    "print(type(X))\r\n",
    "mecab_X = mecab.morphs(X[0])\r\n",
    "print(X[0])\r\n",
    "print(mecab_X)\r\n",
    "\r\n",
    "for i in range(len(X)):\r\n",
    "  X[i] = mecab.morphs(X[i])\r\n",
    "print(X)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1 2 3]\n",
      "[0 0 0 ... 2 2 2]\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n",
      "<class 'pandas.core.series.Series'>\n",
      "민준\n",
      "['민준']\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\kim\\.conda\\envs\\exam_cv2\\lib\\site-packages\\ipykernel_launcher.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0            [민준]\n",
      "1            [서준]\n",
      "2            [도윤]\n",
      "3            [시우]\n",
      "4            [주원]\n",
      "            ...    \n",
      "59899      [희, 해]\n",
      "59900      [희, 활]\n",
      "59901    [히, 까리]\n",
      "59902    [히이, 로]\n",
      "59903    [힐드, 로]\n",
      "Name: name, Length: 59904, dtype: object\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "token = Tokenizer()\r\n",
    "token.fit_on_texts(X)\r\n",
    "tokened_X = token.texts_to_sequences(X)\r\n",
    "print(tokened_X[0])\r\n",
    "\r\n",
    "with open('./model/gender_token_mecab.pickle', 'wb') as f:\r\n",
    "    pickle.dump(token, f)\r\n",
    "\r\n",
    "wordsize = len(token.word_index) + 1\r\n",
    "print(wordsize)\r\n",
    "\r\n",
    "max = 0\r\n",
    "for i in range(len(tokened_X)):\r\n",
    "    if max < len(tokened_X[i]):\r\n",
    "        max = len(tokened_X[i])\r\n",
    "print(max)\r\n",
    "\r\n",
    "X_pad = pad_sequences(tokened_X, max)\r\n",
    "print(X_pad[:10])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[441]\n",
      "25827\n",
      "8\n",
      "[[  0   0   0   0   0   0   0 441]\n",
      " [  0   0   0   0   0   0   0 532]\n",
      " [  0   0   0   0   0   0   0 996]\n",
      " [  0   0   0   0   0   0   0 354]\n",
      " [  0   0   0   0   0   0   0 427]\n",
      " [  0   0   0   0   0   0   0 428]\n",
      " [  0   0   0   0   0   0   0 292]\n",
      " [  0   0   0   0   0   0   0 416]\n",
      " [  0   0   0   0   0   0   0 506]\n",
      " [  0   0   0   0   0   0   0 482]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(\r\n",
    "    X_pad, onehot_Y, test_size=0.2)\r\n",
    "print(X_train.shape)\r\n",
    "print(X_test.shape)\r\n",
    "print(Y_train.shape)\r\n",
    "print(Y_test.shape)\r\n",
    "\r\n",
    "xy = X_train, X_test, Y_train, Y_test\r\n",
    "np.save('./model/gender_data_max_{}_size_{}'.format(max, wordsize), xy)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(47923, 8)\n",
      "(11981, 8)\n",
      "(47923, 3)\n",
      "(11981, 3)\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('exam_cv2': conda)"
  },
  "interpreter": {
   "hash": "19a2027c367e4a8fbf50703f7b521df71edff403eb9eba2200ef5f1febf03a5b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}