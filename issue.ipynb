{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#현재 시간 설정\r\n",
    "from datetime import datetime, date, time, timedelta\r\n",
    "\r\n",
    "now = datetime.now()\r\n",
    "nowDatetime = now.strftime('%Y-%m-%d %H:%M')\r\n",
    "print(nowDatetime)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2021-08-27 23:28\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "########### 이슈 빼오기 ########\r\n",
    "import requests\r\n",
    "from bs4 import BeautifulSoup\r\n",
    "\r\n",
    "url = 'https://www.issuelink.co.kr/community/listview/all/3/adj/_self/blank/blank/blank'\r\n",
    "headers = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.85 Safari/537.36'}\r\n",
    "html_rank = requests.get(url, headers=headers).text\r\n",
    "soup_rank = BeautifulSoup(html_rank, 'lxml')\r\n",
    "# keyword = soup_rank.select('div > div:nth-of-type(2) > div:nth-of-type(4) > div.ibox.float-e-margins > div ')\r\n",
    "keywords = soup_rank.select('div.ibox.float-e-margins > div > table > tbody > tr > td > a')\r\n",
    "\r\n",
    "\r\n",
    "key_list = []\r\n",
    "for k in keywords:\r\n",
    "    keyword = k.text\r\n",
    "    key_list.append(keyword)\r\n",
    "\r\n",
    "###### 7시를 기준으로 기준 리스트를 하나 만들어야 함 / datetime에서 시간 분만 빼와서 if로 비교\r\n",
    "##### 7시 기준이 아닐 때 \r\n",
    "\r\n",
    "key_list.pop(0)\r\n",
    "print(key_list)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['호날두', '일본', '아프간', '한국', '펜트하우스', '이재명', '윤희숙', '법무부', '플립', '김용호', '도깨비', '블리치', '로아', '윤석열', '홍준표', '보라', '이야기', '코로나', '미국', '레전드', '아이돌', '이낙연', '아파트', '민주당', '유튜브', '중국', '갤럭시', '정윤종', '마지막']\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "### 이슈 실제 조회수 ###\r\n",
    "\r\n",
    "from bs4 import BeautifulSoup\r\n",
    "import requests\r\n",
    "import urllib\r\n",
    "import operator\r\n",
    "\r\n",
    "sum_list = []\r\n",
    "search_list = key_list\r\n",
    "\r\n",
    "def sum_hit(search) :\r\n",
    "    \r\n",
    "    url = f'https://www.issuelink.co.kr/community/listview/read/3/adj/_self/blank/{search}'\r\n",
    "    headers = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.85 Safari/537.36'}\r\n",
    "    r = requests.get(url, headers=headers)\r\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\r\n",
    "\r\n",
    "    hits = soup.select('span.hit')\r\n",
    "    \r\n",
    "    sum=0\r\n",
    "    \r\n",
    "    for hit in hits :\r\n",
    "        sum += int(hit.text.replace(',',''))\r\n",
    "    \r\n",
    "    sum_list.append(sum)  \r\n",
    "    print('*',end='')\r\n",
    "    \r\n",
    "for search in search_list :\r\n",
    "    sum_hit(search)\r\n",
    "\r\n",
    "#조회수, 키워드 합치기\r\n",
    "sum_search = dict(zip(key_list,sum_list))\r\n",
    "\r\n",
    "#조회수 순으로 정렬\r\n",
    "#a = sorted(sum_search.items(), key=lambda x:x[1], reverse = True)\r\n",
    "\r\n",
    "print()\r\n",
    "print(sum_search)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "*****************************\n",
      "{'호날두': 135071, '일본': 126069, '아프간': 124348, '한국': 128719, '펜트하우스': 12452, '이재명': 25445, '윤희숙': 31888, '법무부': 36026, '플립': 22204, '김용호': 32121, '도깨비': 54311, '블리치': 31913, '로아': 2143, '윤석열': 8096, '홍준표': 6027, '보라': 5639, '이야기': 10234, '코로나': 31626, '미국': 24386, '레전드': 43250, '아이돌': 32196, '이낙연': 12644, '아파트': 29632, '민주당': 6260, '유튜브': 14252, '중국': 78382, '갤럭시': 20462, '정윤종': 2798, '마지막': 15996}\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "#### 키워드 제목 추출 탐30 개별로 ####\r\n",
    "\r\n",
    "from bs4 import BeautifulSoup\r\n",
    "import requests\r\n",
    "import urllib\r\n",
    "import os\r\n",
    "\r\n",
    "#디렉토리 폴더 생성\r\n",
    "path = \"C:/work/python/Asia_GAN/myproject/temp\" #C:\\work\\python\\Asia_GAN\\myproject\r\n",
    "if not os.path.isdir(path):                                                           \r\n",
    "    os.mkdir(path)\r\n",
    "\r\n",
    "keyword_list=[]\r\n",
    "\r\n",
    "def subject(search) :\r\n",
    "    url = f'https://www.issuelink.co.kr/community/listview/all/3/adj/_self/blank/{search}'\r\n",
    "    headers = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/90.0.4430.85 Safari/537.36'}\r\n",
    "    r = requests.get(url, headers=headers)\r\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\r\n",
    "\r\n",
    "    sub = soup.select('span.title')\r\n",
    "    \r\n",
    "    keyword_list.clear()\r\n",
    "    \r\n",
    "    for i in sub :\r\n",
    "        split_string = i.get_text().split(' [',1)\r\n",
    "        substring = split_string[0]    \r\n",
    "        keyword_list.append(substring)\r\n",
    "        \r\n",
    "    with open(f'C:/work/python/Asia_GAN/myproject/temp/{search}.txt','w', encoding = 'utf-8') as file :\r\n",
    "        file.writelines(keyword_list)\r\n",
    "    \r\n",
    "    print('**', end=\"\")\r\n",
    "            \r\n",
    "    \r\n",
    "for search in search_list :\r\n",
    "    subject(search)\r\n",
    "\r\n",
    "print()\r\n",
    "print('완료')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "**********************************************************\n",
      "완료\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "#### 키워드 형태소 카운팅 ####\r\n",
    "\r\n",
    "\"\"\" 형태소 분석기\r\n",
    "    명사 추출 및 빈도수 체크\r\n",
    "    python [모듈 이름] [텍스트 파일명.txt] [결과파일명.txt]\r\n",
    "\"\"\"\r\n",
    "\r\n",
    "import sys\r\n",
    "from konlpy.tag import Twitter\r\n",
    "from collections import Counter\r\n",
    "\r\n",
    "\r\n",
    "def get_tags(text, ntags=50):\r\n",
    "    spliter = Twitter()\r\n",
    "    nouns = spliter.nouns(text)\r\n",
    "    count = Counter(nouns)\r\n",
    "    return_list = []\r\n",
    "    for n, c in count.most_common(ntags):\r\n",
    "        temp = {'tag': n, 'count': c}\r\n",
    "        return_list.append(temp)\r\n",
    "    return return_list\r\n",
    "\r\n",
    "\r\n",
    "def main(search):\r\n",
    "    # 분석할 파일\r\n",
    "    noun_count = 50\r\n",
    "    # count.txt 에 저장\r\n",
    "    open_text_file = open(f'C:/work/python/Asia_GAN/myproject/temp/{search}.txt', 'r',-1,\"utf-8\")\r\n",
    "    # 분석할 파일을 open \r\n",
    "    text = open_text_file.read() #파일을 읽습니다.\r\n",
    "    tags = get_tags(text, noun_count) # get_tags 함수 실행\r\n",
    "    open_text_file.close()   #파일 close\r\n",
    "    open_output_file = open(f\"C:/work/python/Asia_GAN/myproject/temp/{search}-count.txt\", 'w',-1,\"utf-8\")\r\n",
    "    # 결과로 쓰일 count.txt 열기\r\n",
    "    for tag in tags:\r\n",
    "        noun = tag['tag']\r\n",
    "        count = tag['count']\r\n",
    "        open_output_file.write('{} {}\\n'.format(noun, count))\r\n",
    "    # 결과 저장\r\n",
    "    open_output_file.close() \r\n",
    "\r\n",
    "for search in search_list :\r\n",
    "    main(search)\r\n",
    "    \r\n",
    "print('완료')\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\kim\\.conda\\envs\\exam_cv2\\lib\\site-packages\\konlpy\\tag\\_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "완료\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import requests\r\n",
    "from bs4 import BeautifulSoup\r\n",
    "\r\n",
    "sub_key = {}\r\n",
    "\r\n",
    "for i in sum_search :\r\n",
    "      \r\n",
    "    with open(f'C:/work/python/Asia_GAN/myproject/temp/{i}-count.txt','r', encoding = 'utf-8') as file :\r\n",
    "        data = str(file.readlines()[1])\r\n",
    "\r\n",
    "    split_string = data.split(' ',1) \r\n",
    "    substring = split_string[0]           #빈도수 제거 \r\n",
    "    #print(substring)\r\n",
    "    \r\n",
    "    sub_key[i] = substring\r\n",
    "    \r\n",
    "    \r\n",
    "print(sub_key)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'호날두': '맨유', '일본': '아프간', '아프간': '작전', '한국': '아프간', '펜트하우스': '단태', '이재명': '사생활', '윤희숙': '숙', '법무부': '차관', '플립': '갤럭시', '김용호': '방송', '도깨비': '게임', '블리치': '만해', '로아': '좀', '윤석열': '이재명', '홍준표': '이유', '보라': '김보라', '이야기': '지금', '코로나': '검사', '미국': '아프간', '레전드': '기사', '아이돌': '그룹', '이낙연': '이재명', '아파트': '공급', '민주당': '지지자', '유튜브': '김용호', '중국': '보고', '갤럭시': '폴드', '정윤종': '김윤환', '마지막': '김용호'}\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "#네이버 검색, 키워드 서브키워드 \r\n",
    "import requests\r\n",
    "from bs4 import BeautifulSoup\r\n",
    "\r\n",
    "\r\n",
    "art_lists = []\r\n",
    "\r\n",
    "def search(key, b) :\r\n",
    "    \r\n",
    "    art_list = [b]\r\n",
    "    \r\n",
    "    #url = f'https://search.naver.com/search.naver?where=nexearch&sm=top_hty&fbm=1&ie=utf8&query={key}'\r\n",
    "    url = f'https://search.naver.com/search.naver?where=news&sm=tab_jum&query={key}'\r\n",
    "    html = requests.get(url).text\r\n",
    "    soup = BeautifulSoup(html, 'lxml')\r\n",
    "    \r\n",
    "    for i in range(2) :\r\n",
    "        news = soup.select('div.info_group > a:nth-of-type(2)')[i].attrs[\"href\"]\r\n",
    "        art_list.append(news)\r\n",
    "    \r\n",
    "    art_lists.append(art_list)\r\n",
    "    \r\n",
    "a = sorted(sum_search.items(), key=lambda x:x[1], reverse = True) #value 값 기준으로 정렬, 상위 5개 키워드\r\n",
    "\r\n",
    "\r\n",
    "for i in range(5) :\r\n",
    "    b= a[i][0]     #정렬 후 dic -> list 함수로 변환돼서 [i][0]으로 빼옴 \r\n",
    "    #print(b)\r\n",
    "    \r\n",
    "    with open(f'C:/work/python/Asia_GAN/myproject/temp/{b}-count.txt','r', encoding = 'utf-8') as file :\r\n",
    "        data = str(file.readlines()[1])\r\n",
    "\r\n",
    "    split_string = data.split(' ',1) \r\n",
    "    substring = split_string[0]           #빈도수 제거 \r\n",
    "    #print(substring)\r\n",
    "    \r\n",
    "    key = b + \" \" + substring\r\n",
    "    search(key, b)\r\n",
    "    \r\n",
    "print(art_lists)\r\n",
    "print(sum_search.items())\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[['호날두', 'https://sports.news.naver.com/news.nhn?oid=076&aid=0003771921', 'https://sports.news.naver.com/news.nhn?oid=108&aid=0002983994'], ['한국', 'https://news.naver.com/main/read.naver?mode=LSD&mid=sec&sid1=104&oid=001&aid=0012625367', 'https://news.naver.com/main/read.naver?mode=LSD&mid=sec&sid1=100&oid=366&aid=0000757380'], ['일본', 'https://news.naver.com/main/read.naver?mode=LSD&mid=sec&sid1=104&oid=003&aid=0010687901', 'https://news.naver.com/main/read.naver?mode=LSD&mid=sec&sid1=104&oid=417&aid=0000729372'], ['아프간', 'https://news.naver.com/main/read.naver?mode=LSD&mid=sec&sid1=104&oid=022&aid=0003614026', 'https://news.naver.com/main/read.naver?mode=LSD&mid=sec&sid1=100&oid=018&aid=0005021393'], ['중국', 'https://news.naver.com/main/read.naver?mode=LSD&mid=sec&sid1=104&oid=003&aid=0010685077', 'https://news.naver.com/main/read.naver?mode=LSD&mid=sec&sid1=104&oid=056&aid=0011108320']]\n",
      "dict_items([('호날두', 135071), ('일본', 126069), ('아프간', 124348), ('한국', 128719), ('펜트하우스', 12452), ('이재명', 25445), ('윤희숙', 31888), ('법무부', 36026), ('플립', 22204), ('김용호', 32121), ('도깨비', 54311), ('블리치', 31913), ('로아', 2143), ('윤석열', 8096), ('홍준표', 6027), ('보라', 5639), ('이야기', 10234), ('코로나', 31626), ('미국', 24386), ('레전드', 43250), ('아이돌', 32196), ('이낙연', 12644), ('아파트', 29632), ('민주당', 6260), ('유튜브', 14252), ('중국', 78382), ('갤럭시', 20462), ('정윤종', 2798), ('마지막', 15996)])\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "#subject 디렉토리내 파일 삭제하기\r\n",
    "\r\n",
    "import shutil\r\n",
    "\r\n",
    "pathTest = r\"C:/work/python/Asia_GAN/myproject/temp\"\r\n",
    "\r\n",
    "try:\r\n",
    "    shutil.rmtree(pathTest)\r\n",
    "except OSError as e:\r\n",
    "    print(e)\r\n",
    "else:\r\n",
    "    print(\"The directory is deleted successfully\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The directory is deleted successfully\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "#### 새로운 파일 생성 ###\r\n",
    "\r\n",
    "import os\r\n",
    "from datetime import datetime, date, time, timedelta\r\n",
    "import datetime\r\n",
    "import openpyxl\r\n",
    "import pickle\r\n",
    "\r\n",
    "#디렉토리 폴더 생성\r\n",
    "path = \"C:/work/python/Asia_GAN/myproject/output\"\r\n",
    "if not os.path.isdir(path):                                                           \r\n",
    "    os.mkdir(path)\r\n",
    "\r\n",
    "\r\n",
    "today =datetime.datetime.now()\r\n",
    "\r\n",
    "hms = today.strftime('%H:%M:%S') #시분초\r\n",
    "ymd = today.strftime('%Y-%m-%d') #년월일  - 오늘 날짜\r\n",
    "yesterday = (today - datetime.timedelta(1)).strftime('%Y-%m-%d') #어제날짜\r\n",
    "\r\n",
    "wb = openpyxl.Workbook()\r\n",
    "\r\n",
    "\r\n",
    "if hms < '19:00:00':\r\n",
    "    file_name = yesterday\r\n",
    "    path2 = f\"C:/work/python/Asia_GAN/myproject/output/{file_name}.xlsx\"\r\n",
    "    \r\n",
    "    if not os.path.isfile(path2):  \r\n",
    "        wb.save(path2)\r\n",
    "        print('파일 생성완료1')\r\n",
    "\r\n",
    "    else :\r\n",
    "        print('파일을 작업중입니다....')\r\n",
    "\r\n",
    "else : \r\n",
    "    file_name = ymd\r\n",
    "    path2 = f\"C:/work/python/Asia_GAN/myproject/output/{file_name}.xlsx\"\r\n",
    "    \r\n",
    "    if not os.path.isfile(path2):  \r\n",
    "        wb.save(path2)\r\n",
    "        print('파일 생성완료2')\r\n",
    "\r\n",
    "    else :\r\n",
    "        print('파일을 작업중입니다....')\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "파일을 작업중입니다....\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "#### 행 생성 ####\r\n",
    "\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from itertools import chain\r\n",
    "# import xlsxwriter\r\n",
    "\r\n",
    "#복제\r\n",
    "key_lists = list(chain.from_iterable(zip(key_list,key_list))) #멀티 인덱스를 위해서 [a,b,c] => [a,a,b,b,c,c] 로 만들어줌\r\n",
    "multi_keys = ['조회수','서브키워드'] * len(key_list)\r\n",
    "\r\n",
    "# 조회수, 서브 키워드 입력\r\n",
    "def hit_sub(i, time) :\r\n",
    "    df1.loc[time][(i,'조회수')] = sum_search[i]\r\n",
    "    df1.loc[time][(i,'서브키워드')] = sub_key[i]\r\n",
    "    \r\n",
    "# generate time series index\r\n",
    "time = nowDatetime    #현재 시간 설정\r\n",
    "\r\n",
    "df1 = pd.DataFrame(columns = [key_lists, multi_keys],index = [time])\r\n",
    "\r\n",
    "for i in sum_search : \r\n",
    "    hit_sub(i, time)\r\n",
    "    \r\n",
    "#### 다음 행에 추가 ####\r\n",
    "df = pd.read_excel(path2, header=[0,1], index_col=[0] )   #number 해결\r\n",
    "df = df.append(df1, sort=False)    #컬럼 수가 다를 때 NaN 값을 넣고 행 추가\r\n",
    "\r\n",
    "# ##### 열 너비 조정 ####\r\n",
    "# writer = pd.ExcelWriter(path2, engine='xlsxwriter')\r\n",
    "# df.to_excel(writer, sheet_name=\"Sheet1\")\r\n",
    "# workbook = writer.book\r\n",
    "# worksheet = writer.sheets[\"Sheet1\"]\r\n",
    "# worksheet.set_column('A:A', 20)\r\n",
    "# writer.save()\r\n",
    "# print('행 추가 완료')"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#### 상위 5개 키워드 ####\r\n",
    "\r\n",
    "df = pd.read_excel(path2, header=[0,1], index_col=[0] )\r\n",
    "df_col = list(df.columns.levels[0])\r\n",
    "\r\n",
    "hit_top5 = []\r\n",
    "\r\n",
    "for i in df_col :\r\n",
    "    hit_max = df[i,'조회수'].max()\r\n",
    "    hit_top5.append(hit_max)\r\n",
    "\r\n",
    "hit_dict = dict(zip(df_col,hit_top5)) #딕셔너리 값으로 저장\r\n",
    "\r\n",
    "keyword_top5 = sorted(hit_dict, key=hit_dict.get, reverse = True)[:5] #탑 5개 keyword 추출\r\n",
    "print(keyword_top5)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-2aa3fda83958>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#### 상위 5개 키워드 ####\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mdf_col\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlevels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#### 19시에 코드 보내기\r\n",
    "\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "\r\n",
    "title_font = {'fontsize': 16, 'fontweight': 'bold'}\r\n",
    "plt.rc('font',family='Malgun Gothic')\r\n",
    "plt.figure(figsize=[20,10])\r\n",
    "plt.style.use('ggplot')\r\n",
    "plt.show(block=False)\r\n",
    "plt.pause(1)\r\n",
    "plt.close()\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "출처: https://theonly1.tistory.com/2470 [Be the only one, not the best one]\r\n",
    "\r\n",
    "ymd = today.strftime('%Y-%m-%d') \r\n",
    "hms = '19:00:00'\r\n",
    "\r\n",
    "if hms == '19:00:00':\r\n",
    "    path_png = \"C:/Workspace/project2_final/output/graphs\"\r\n",
    "    if not os.path.isdir(path_png):                                                           \r\n",
    "        os.mkdir(path_png)\r\n",
    "    \r\n",
    "    path_date = f\"C:/Workspace/project2_final/output/graphs/{ymd}\"\r\n",
    "    if not os.path.isdir(path_date):                                                           \r\n",
    "        os.mkdir(path_date)    \r\n",
    "    \r\n",
    "    ##### 그래프 조회수 변동 ######\r\n",
    "    for i in keyword_top5 :\r\n",
    "        plt.title (f\"키워드 : '{i}' 조회수 변동\", fontsize=20)\r\n",
    "        df.index,df[i,'조회수'].plot( kind='bar')\r\n",
    "        #    plt.bar(df.index,df[i,'조회수'])\r\n",
    "        #plt.show()\r\n",
    "        plt.savefig(f'{path_date}/조회수변동-({i}).png', bbox_inches='tight')\r\n",
    "        plt.close()\r\n",
    "                 #.plot( kind='bar')\r\n",
    "\r\n",
    "    ##### 그래프 키워드 관심도 #####\r\n",
    "    for i in keyword_top5 :\r\n",
    "        text =f'{i} 키워드 관심도'\r\n",
    "        sub_keys = df[i].groupby(['서브키워드'])['조회수'].mean().sort_values()\r\n",
    "        plt.title(text, fontdict=title_font, loc='center', pad= 20)\r\n",
    "        sub_keys.plot(kind='pie', autopct = '%1.1f%%', shadow = True, startangle=110 )\r\n",
    "        #plt.show()\r\n",
    "\r\n",
    "        plt.savefig(f'{path_date}/관심도-({i}).png')\r\n",
    "        plt.close()\r\n",
    "    \r\n",
    "    print('그래프 시각화 완료')\r\n",
    "    \r\n",
    " \r\n",
    "    \r\n"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 1440x720 with 0 Axes>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "그래프 시각화 완료\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('exam_cv2': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "interpreter": {
   "hash": "19a2027c367e4a8fbf50703f7b521df71edff403eb9eba2200ef5f1febf03a5b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}