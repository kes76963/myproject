{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "- 댓글 크롤링 시간 줄이는 방법? (sleep, implicitly_wait 섞으면서 해결)\r\n",
    "- 셀레니움 => bs4 페이지 소스는 가져올 수 있지만, 페이지 옵션 적용이 안 돼서 영어 번역 x  (해결함)\r\n",
    "- 모든 댓글 크롤링할 필요는 있을까? 시청자 성향 알기 위해서 우선 다수의 의견 반영이 돼야 함\r\n",
    "  => 대댓글 성향 : 의견에 반대 or 공감 \r\n",
    "        if 반대 : 원래 절대적인 반대 의견이 많지 않지만, 서로 댓글로 싸우면서 카운팅이 많아질 것(데이터 오류 생김), 욕설 난무 \r\n",
    "        else :  ㅋㅋㅋㅋㅋ 위주의 댓글, 있으나 없으나 상관 없음. 부정적인 댓글이 아닐 경우 댓글이 많이 달리지 않고 추천이 달림.\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# 옵션들\r\n",
    "from selenium import webdriver\r\n",
    "# from selenium.webdriver.chrome.options import Options\r\n",
    "# from selenium.webdriver.common.keys import Keys\r\n",
    "# from selenium.webdriver.common.action_chains import ActionChains\r\n",
    "from bs4 import BeautifulSoup\r\n",
    "from selenium import webdriver\r\n",
    "from selenium.webdriver.common.keys import Keys\r\n",
    "import time\r\n",
    "\r\n",
    "options = webdriver.ChromeOptions() # 크롬 옵션 객체 생성\r\n",
    "user_agent = \"Mozilla/5.0 (Windows NT 4.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2049.0 Safari/537.36 \"\r\n",
    "options.add_argument('user-agent=' + user_agent)\r\n",
    "#options.add_argument('headless') # headless 모드 설정\r\n",
    "options.add_argument(\"window-size=1920x1080\") # 화면크기(전체화면)\r\n",
    "options.add_argument(\"disable-gpu\") \r\n",
    "options.add_argument(\"disable-infobars\")\r\n",
    "options.add_argument(\"--disable-extensions\")\r\n",
    "options.add_argument(\"--mute-audio\") #mute\r\n",
    "# options.add_argument(\"--lang=ko_KR\") # 가짜 플러그인 탑재\r\n",
    "# options.add_argument(\"--lang=ko\") # 가짜 플러그인 탑재\r\n",
    "# options.add_argument('--blink-settings=imagesEnabled=false') #브라우저에서 이미지 로딩을 하지 않습니다.\r\n",
    "options.add_argument('incognito') #시크릿 모드의 브라우저가 실행됩니다.\r\n",
    "options.add_argument(\"--start-maximized\")\r\n",
    "#options.add_argument('--kiosk') f11\r\n",
    "\r\n",
    "#1\r\n",
    "prefs = {\r\n",
    "  \"translate_whitelists\": {\"en\":\"ko\"},\r\n",
    "  \"translate\":{\"enabled\":\"true\"}\r\n",
    "}\r\n",
    "options.add_experimental_option(\"prefs\", prefs)\r\n",
    "\r\n",
    "#2\r\n",
    "prefs = {\r\n",
    "  \"translate_whitelists\": {\"your native language\":\"ko\"},\r\n",
    "  \"translate\":{\"enabled\":\"True\"}\r\n",
    "}\r\n",
    "options.add_experimental_option(\"prefs\", prefs)\r\n",
    "\r\n",
    "#3\r\n",
    "options.add_experimental_option('prefs', {'intl.accept_languages': 'ko,ko_kr'})\r\n",
    "\r\n",
    "# 속도 향상을 위한 옵션 해제\r\n",
    "# prefs = {'profile.default_content_setting_values': {'cookies' : 2, 'images': 2, 'plugins' : 2, 'popups': 2, 'geolocation': 2, 'notifications' : 2, 'auto_select_certificate': 2, 'fullscreen' : 2, 'mouselock' : 2, 'mixed_script': 2, 'media_stream' : 2, 'media_stream_mic' : 2, 'media_stream_camera': 2, 'protocol_handlers' : 2, 'ppapi_broker' : 2, 'automatic_downloads': 2, 'midi_sysex' : 2, 'push_messaging' : 2, 'ssl_cert_decisions': 2, 'metro_switch_to_desktop' : 2, 'protected_media_identifier': 2, 'app_banner': 2, 'site_engagement' : 2, 'durable_storage' : 2}}   \r\n",
    "# options.add_experimental_option('prefs', prefs)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "from selenium.webdriver.common.action_chains import ActionChains\r\n",
    "import pyautogui\r\n",
    "\r\n",
    "driver = webdriver.Chrome('chromedriver.exe', options= options)\r\n",
    "url = \"https://edition.cnn.com/\"\r\n",
    "driver.get(url)\r\n",
    "time.sleep(1)\r\n",
    "\r\n",
    "action = webdriver.ActionChains(driver)\r\n",
    "\r\n",
    "## Trying to use ActionChains\r\n",
    "action.send_keys(Keys.SHIFT, Keys.F10, 't').perform()\r\n",
    "\r\n",
    "## Trying to use ActionChain key down\r\n",
    "action.key_down(Keys.SHIFT).key_down(Keys.F10).send_keys(\"t\").perform()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "from selenium.webdriver.common.action_chains import ActionChains\r\n",
    "import pyautogui\r\n",
    "\r\n",
    "driver = webdriver.Chrome('chromedriver.exe', options= options)\r\n",
    "url = \"https://edition.cnn.com/\"\r\n",
    "driver.get(url)\r\n",
    "time.sleep(1)\r\n",
    "\r\n",
    "# 키보드 핫키\r\n",
    "pyautogui.hotkey('shift','F10')\r\n",
    "for i in range(7):\r\n",
    "    pyautogui.hotkey('down')\r\n",
    "pyautogui.hotkey('enter')\r\n",
    "\r\n",
    "\r\n",
    "# 액션  안 됨\r\n",
    "# actions = ActionChains(driver)\r\n",
    "# actions.send_keys(Keys.SHIFT + Keys.F10 + 't')\r\n",
    "# actions.perform()\r\n",
    "# actions.key_down(Keys.SHIFT).key_down(Keys.F10).send_keys('t').key_up(Keys.SHIFT).key_up(Keys.F10).perform()\r\n",
    "# actions.key_down(Keys.SHIFT).key_down(Keys.F10).send_Keys(Keys.ARROW_DOWN).sendKeys(Keys.ARROW_DOWN).sendKeys(Keys.RETURN).build().perform()\r\n",
    "time.sleep(0.5)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "body = driver.find_element_by_tag_name('body')\r\n",
    "time.sleep(0.5)\r\n",
    "num_of_pagedowns = 2\r\n",
    "while num_of_pagedowns:\r\n",
    "    body.send_keys(Keys.PAGE_DOWN)\r\n",
    "    time.sleep(0.5)\r\n",
    "    num_of_pagedowns -= 1\r\n",
    "    driver.implicitly_wait(1)       \r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from bs4 import BeautifulSoup\r\n",
    "from selenium import webdriver\r\n",
    "from selenium.webdriver.common.keys import Keys\r\n",
    "import time\r\n",
    "\r\n",
    "driver = webdriver.Chrome('C:/work/python/Asia_GAN/myproject/youtube/chromedriver.exe', options= options)\r\n",
    "url = \"https://www.youtube.com/c/NetflixKorea/videos\"\r\n",
    "driver.get(url)\r\n",
    "\r\n",
    "# 스크롤 다운\r\n",
    "time.sleep(5)\r\n",
    "endk = 5\r\n",
    "while endk:\r\n",
    "    driver.find_element_by_tag_name('body').send_keys(Keys.END)\r\n",
    "    time.sleep(0.3)\r\n",
    "    endk -= 1\r\n",
    "\r\n",
    "# bs4 실행    \r\n",
    "html = driver.page_source\r\n",
    "soup = BeautifulSoup(html, 'lxml')\r\n",
    "\r\n",
    "video_list0 = soup.find('div', {'id': 'contents'})\r\n",
    "video_list2 = video_list0.find_all('ytd-grid-video-renderer',{'class':'style-scope ytd-grid-renderer'})\r\n",
    "\r\n",
    "base_url = 'http://www.youtube.com'\r\n",
    "video_url = []\r\n",
    "\r\n",
    "# 반복문을 실행시켜 비디오의 주소를 video_url에 넣는다.\r\n",
    "for i in range(len(video_list2)):\r\n",
    "    url = base_url+video_list2[i].find('a',{'id':'thumbnail'})['href']\r\n",
    "    video_url.append(url)\r\n",
    "    \r\n",
    "print(video_url)\r\n",
    "\r\n",
    "driver.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "from bs4 import BeautifulSoup\r\n",
    "import time\r\n",
    "import pandas as pd\r\n",
    "import requests\r\n",
    "import re\r\n",
    "from selenium.webdriver.common.action_chains import ActionChains\r\n",
    "import pyautogui\r\n",
    "\r\n",
    "\r\n",
    "def crawl_youtube_page_html_sources(video_url):\r\n",
    "    html_sources = []\r\n",
    "\r\n",
    "    for i in range(0,len(video_url)):\r\n",
    "        driver = webdriver.Chrome('C:/work/python/Asia_GAN/myproject/youtube/chromedriver.exe', options= options)\r\n",
    "        # driver.implicitly_wait(0.5)\r\n",
    "        driver.get(video_url[i])\r\n",
    "        pyautogui.hotkey('shift','F10')\r\n",
    "        for i in range(7):\r\n",
    "            pyautogui.hotkey('down')\r\n",
    "        pyautogui.hotkey('enter')\r\n",
    "        time.sleep(0.5)\r\n",
    "\r\n",
    "        body = driver.find_element_by_tag_name('body')\r\n",
    "        \r\n",
    "        actions = ActionChains(driver)\r\n",
    "        actions.send_keys(Keys.SHIFT + Keys.F10 + 't')\r\n",
    "        actions.perform()\r\n",
    "        time.sleep(0.5)\r\n",
    "\r\n",
    "        #댓글 null 값 오류 방지 위해서 집어 넣음\r\n",
    "        num_of_pagedowns = 1\r\n",
    "        while num_of_pagedowns:\r\n",
    "            body.send_keys(Keys.PAGE_DOWN)\r\n",
    "            time.sleep(0.5)\r\n",
    "            num_of_pagedowns -= 1\r\n",
    "            driver.implicitly_wait(1)\r\n",
    "\r\n",
    "        last_page_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\r\n",
    "\r\n",
    "        while True:\r\n",
    "            driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\r\n",
    "            # driver.implicitly_wait(2) #오류남\r\n",
    "            time.sleep(0.5)\r\n",
    "            new_page_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\r\n",
    "\r\n",
    "            if new_page_height == last_page_height:\r\n",
    "                break\r\n",
    "            last_page_height = new_page_height\r\n",
    "            driver.implicitly_wait(1)\r\n",
    "\r\n",
    "        html_source = driver.page_source\r\n",
    "        html_sources.append(html_source)\r\n",
    "        print(\"OK\")\r\n",
    "\r\n",
    "        driver.quit()\r\n",
    "    return html_sources\r\n",
    "\r\n",
    "def get_user_IDs_and_comments(html_sources):\r\n",
    "    my_dataframes = []\r\n",
    "    titles = []\r\n",
    "    for html in html_sources:\r\n",
    "        \r\n",
    "        soup = BeautifulSoup(html, 'lxml')\r\n",
    "        \r\n",
    "        youtube_title = soup.find('h1',{'class':'title style-scope ytd-video-primary-info-renderer'}).text.replace(',','')\r\n",
    "        titles.append(youtube_title)\r\n",
    "        \r\n",
    "        #유튜브 닉네임, 유튜브 댓글       \r\n",
    "        youtube_user_IDs = soup.select(\"div#header-author > h3 > #author-text > span\")\r\n",
    "        youtube_comments = soup.select(\"yt-formatted-string#content-text\")\r\n",
    "        \r\n",
    "        str_youtube_userIDs = []\r\n",
    "        str_youtube_comments = []\r\n",
    "        \r\n",
    "        \r\n",
    "        for i in range(len(youtube_user_IDs)):\r\n",
    "            str_tmp = str(youtube_user_IDs[i].text)\r\n",
    "        #     print(str_tmp)\r\n",
    "            str_tmp = str_tmp.replace('\\n', '')\r\n",
    "            str_tmp = str_tmp.replace('\\t', '')\r\n",
    "            str_tmp = str_tmp.replace('                ','')\r\n",
    "            str_youtube_userIDs.append(str_tmp)\r\n",
    "\r\n",
    "            str_tmp = str(youtube_comments[i].text) \r\n",
    "            str_tmp = str_tmp.replace('\\n', '')\r\n",
    "            str_tmp = str_tmp.replace('\\t', '')\r\n",
    "            str_tmp = str_tmp.replace('            ', '')\r\n",
    "\r\n",
    "            str_youtube_comments.append(str_tmp)\r\n",
    "            \r\n",
    "        pd_data = {\"ID\":str_youtube_userIDs, \"Comment\":str_youtube_comments}\r\n",
    "\r\n",
    "        youtube_pd = pd.DataFrame(pd_data)\r\n",
    "\r\n",
    "        my_dataframes.append(youtube_pd)\r\n",
    "        \r\n",
    "    return my_dataframes, titles\r\n",
    "\r\n",
    "def convert_csv_from_dataframe(titles, my_dataframes):\r\n",
    "    for i in range(len(my_dataframes)):\r\n",
    "        title = re.sub('[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…《\\》]', '', titles[i])\r\n",
    "        my_dataframes[i].to_csv(\"{}.csv\".format(title))\r\n",
    "        \r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from bs4 import BeautifulSoup\r\n",
    "import time\r\n",
    "import pandas as pd\r\n",
    "import requests\r\n",
    "import re\r\n",
    "\r\n",
    "def crawl_youtube_page_html_sources(video_url):\r\n",
    "    html_sources = []\r\n",
    "\r\n",
    "    for i in range(0,len(video_url)):\r\n",
    "        driver = webdriver.Chrome('C:/work/python/Asia_GAN/myproject/youtube/chromedriver.exe', options= options)\r\n",
    "        # driver.implicitly_wait(0.5)\r\n",
    "        driver.get(video_url[i])\r\n",
    "        body = driver.find_element_by_tag_name('body')\r\n",
    "        time.sleep(5)\r\n",
    "\r\n",
    "        #댓글 null 값 오류 방지 위해서 집어 넣음\r\n",
    "        num_of_pagedowns = 1\r\n",
    "        while num_of_pagedowns:\r\n",
    "            body.send_keys(Keys.PAGE_DOWN)\r\n",
    "            time.sleep(0.5)\r\n",
    "            num_of_pagedowns -= 1\r\n",
    "            driver.implicitly_wait(1)\r\n",
    "\r\n",
    "        last_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\r\n",
    "\r\n",
    "        while True:\r\n",
    "            driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\r\n",
    "\r\n",
    "            time.sleep(1)\r\n",
    "\r\n",
    "            new_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\r\n",
    "\r\n",
    "            if new_height == last_height:\r\n",
    "                break\r\n",
    "                    \r\n",
    "            last_height = new_height\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "        time.sleep(10)\r\n",
    "        html_source = driver.page_source\r\n",
    "        html_sources.append(html_source)\r\n",
    "        print(\"OK\")\r\n",
    "\r\n",
    "        driver.quit()\r\n",
    "    return html_sources\r\n",
    "\r\n",
    "def get_user_IDs_and_comments(html_sources):\r\n",
    "    my_dataframes = []\r\n",
    "    titles = []\r\n",
    "    for html in html_sources:\r\n",
    "        \r\n",
    "        soup = BeautifulSoup(html, 'lxml')\r\n",
    "        \r\n",
    "        youtube_title = soup.find('h1',{'class':'title style-scope ytd-video-primary-info-renderer'}).text.replace(',','')\r\n",
    "        titles.append(youtube_title)\r\n",
    "        \r\n",
    "        #유튜브 닉네임, 유튜브 댓글       \r\n",
    "        youtube_user_IDs = soup.select(\"div#header-author > h3 > #author-text > span\")\r\n",
    "        youtube_comments = soup.select(\"yt-formatted-string#content-text\")\r\n",
    "        \r\n",
    "        str_youtube_userIDs = []\r\n",
    "        str_youtube_comments = []\r\n",
    "        \r\n",
    "        \r\n",
    "        for i in range(len(youtube_user_IDs)):\r\n",
    "            str_tmp = str(youtube_user_IDs[i].text)\r\n",
    "        #     print(str_tmp)\r\n",
    "            str_tmp = str_tmp.replace('\\n', '')\r\n",
    "            str_tmp = str_tmp.replace('\\t', '')\r\n",
    "            str_tmp = str_tmp.replace('                ','')\r\n",
    "            str_youtube_userIDs.append(str_tmp)\r\n",
    "\r\n",
    "            str_tmp = str(youtube_comments[i].text) \r\n",
    "            str_tmp = str_tmp.replace('\\n', '')\r\n",
    "            str_tmp = str_tmp.replace('\\t', '')\r\n",
    "            str_tmp = str_tmp.replace('            ', '')\r\n",
    "\r\n",
    "            str_youtube_comments.append(str_tmp)\r\n",
    "            \r\n",
    "        pd_data = {\"ID\":str_youtube_userIDs, \"Comment\":str_youtube_comments}\r\n",
    "\r\n",
    "        youtube_pd = pd.DataFrame(pd_data)\r\n",
    "\r\n",
    "        my_dataframes.append(youtube_pd)\r\n",
    "        \r\n",
    "    return my_dataframes, titles\r\n",
    "\r\n",
    "def convert_csv_from_dataframe(titles, my_dataframes):\r\n",
    "    for i in range(len(my_dataframes)):\r\n",
    "        title = re.sub('[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…《\\》]', '', titles[i])\r\n",
    "        my_dataframes[i].to_csv(\"{}.csv\".format(title))\r\n",
    "        \r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "#유튜브 답글 다 클릭하기\r\n",
    "from bs4 import BeautifulSoup\r\n",
    "import time\r\n",
    "import pandas as pd\r\n",
    "import requests\r\n",
    "import re\r\n",
    "\r\n",
    "def crawl_youtube_page_html_sources(video_url):\r\n",
    "    html_sources = []\r\n",
    "\r\n",
    "    for i in range(0,len(video_url)):\r\n",
    "        driver = webdriver.Chrome('C:/work/python/Asia_GAN/myproject/youtube/chromedriver.exe', options= options)\r\n",
    "        # driver.implicitly_wait(0.5)\r\n",
    "        driver.get(video_url[i])\r\n",
    "        body = driver.find_element_by_tag_name('body')\r\n",
    "        time.sleep(1)\r\n",
    "\r\n",
    "        #댓글 null 값 오류 방지 위해서 집어 넣음\r\n",
    "        num_of_pagedowns = 1\r\n",
    "        while num_of_pagedowns:\r\n",
    "            body.send_keys(Keys.PAGE_DOWN)\r\n",
    "            time.sleep(0.5)\r\n",
    "            num_of_pagedowns -= 1\r\n",
    "            driver.implicitly_wait(1)\r\n",
    "\r\n",
    "        last_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\r\n",
    "\r\n",
    "        while True:\r\n",
    "            driver.execute_script(\"window.scrollTo(0, document.documentElement.scrollHeight);\")\r\n",
    "\r\n",
    "            time.sleep(1)\r\n",
    "\r\n",
    "            new_height = driver.execute_script(\"return document.documentElement.scrollHeight\")\r\n",
    "\r\n",
    "            if new_height == last_height:\r\n",
    "                break\r\n",
    "                    \r\n",
    "            last_height = new_height\r\n",
    "        \r\n",
    "        #프리미엄 창 닫기\r\n",
    "        try:\r\n",
    "            driver.find_element_by_css_selector(\"#dismiss-button > a\").click()\r\n",
    "        except:\r\n",
    "            pass\r\n",
    "        \r\n",
    "        #유튜브 답글 열기\r\n",
    "        try : \r\n",
    "            buttons = driver.find_elements_by_css_selector(\"#more-replies > a\")\r\n",
    "\r\n",
    "            time.sleep(0.5)\r\n",
    "\r\n",
    "            for button in buttons:\r\n",
    "                button.send_keys(Keys.ENTER)\r\n",
    "                time.sleep(0.5)\r\n",
    "                button.click()\r\n",
    "                driver.implicitly_wait(0.5)\r\n",
    "        except :\r\n",
    "            print('답글을 다 눌렀거나 없습니다.')\r\n",
    "\r\n",
    "        time.sleep(0.5)\r\n",
    "        html_source = driver.page_source\r\n",
    "        html_sources.append(html_source)\r\n",
    "        print(\"OK\")\r\n",
    "\r\n",
    "        driver.quit()\r\n",
    "    return html_sources\r\n",
    "\r\n",
    "def get_user_IDs_and_comments(html_sources):\r\n",
    "    my_dataframes = []\r\n",
    "    titles = []\r\n",
    "    for html in html_sources:\r\n",
    "        \r\n",
    "        soup = BeautifulSoup(html, 'lxml')\r\n",
    "        \r\n",
    "        youtube_title = soup.find('h1',{'class':'title style-scope ytd-video-primary-info-renderer'}).text.replace(',','')\r\n",
    "        titles.append(youtube_title)\r\n",
    "        \r\n",
    "        #유튜브 닉네임, 유튜브 댓글       \r\n",
    "        youtube_user_IDs = soup.select(\"div#header-author > h3 > #author-text > span\")\r\n",
    "        youtube_comments = soup.select(\"yt-formatted-string#content-text\")\r\n",
    "        \r\n",
    "        \r\n",
    "        str_youtube_userIDs = []\r\n",
    "        str_youtube_comments = []\r\n",
    "        \r\n",
    "        \r\n",
    "        for i in range(len(youtube_user_IDs)):\r\n",
    "            str_tmp = str(youtube_user_IDs[i].text)\r\n",
    "        #     print(str_tmp)\r\n",
    "            str_tmp = str_tmp.replace('\\n', '')\r\n",
    "            str_tmp = str_tmp.replace('              ', '')\r\n",
    "            str_tmp = str_tmp.replace('            ','')\r\n",
    "            str_youtube_userIDs.append(str_tmp)\r\n",
    "\r\n",
    "            str_tmp = str(youtube_comments[i].text) \r\n",
    "            str_tmp = str_tmp.replace('\\n', '')\r\n",
    "            str_tmp = str_tmp.replace('\\t', '')\r\n",
    "            str_tmp = str_tmp.replace('            ', '')\r\n",
    "\r\n",
    "            str_youtube_comments.append(str_tmp)\r\n",
    "            \r\n",
    "        pd_data = {\"ID\":str_youtube_userIDs, \"Comment\":str_youtube_comments}\r\n",
    "\r\n",
    "        youtube_pd = pd.DataFrame(pd_data)\r\n",
    "\r\n",
    "        my_dataframes.append(youtube_pd)\r\n",
    "        \r\n",
    "    return my_dataframes, titles\r\n",
    "\r\n",
    "def convert_csv_from_dataframe(titles, my_dataframes):\r\n",
    "    for i in range(len(my_dataframes)):\r\n",
    "        title = re.sub('[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…《\\》]', '', titles[i])\r\n",
    "        my_dataframes[i].to_csv(f\"{title}.csv\", encoding = 'utf-8-sig')\r\n",
    "        \r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "video_url = ['https://www.youtube.com/watch?v=yQozPVwFGZA'] # 임시 url 실험 'https://www.youtube.com/watch?v=3dGegDKq_HE'\r\n",
    "html_sources = crawl_youtube_page_html_sources(video_url)\r\n",
    "my_dataframes, titles = get_user_IDs_and_comments(html_sources)\r\n",
    "convert_csv_from_dataframe(titles, my_dataframes)\r\n",
    "\r\n",
    "print('완료')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "OK\n",
      "완료\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('exam_cv2': conda)"
  },
  "interpreter": {
   "hash": "19a2027c367e4a8fbf50703f7b521df71edff403eb9eba2200ef5f1febf03a5b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}