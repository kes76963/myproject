{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from transformers import AutoTokenizer, AutoModelWithLMHead\r\n",
    "  \r\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"skt/ko-gpt-trinity-1.2B-v0.5\")\r\n",
    "\r\n",
    "model = AutoModelWithLMHead.from_pretrained(\"skt/ko-gpt-trinity-1.2B-v0.5\")"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Unrecognized model identifier in skt/ko-gpt-trinity-1.2B-v0.5. Should contains one of 'bert', 'openai-gpt', 'gpt2', 'transfo-xl', 'xlnet', 'xlm', 'roberta', 'camembert', 'ctrl'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp/ipykernel_10400/2903974514.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAutoModelWithLMHead\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"skt/ko-gpt-trinity-1.2B-v0.5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAutoModelWithLMHead\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"skt/ko-gpt-trinity-1.2B-v0.5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\exam_cv2\\lib\\site-packages\\transformers\\tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m         raise ValueError(\"Unrecognized model identifier in {}. Should contains one of \"\n\u001b[0;32m    128\u001b[0m                          \u001b[1;34m\"'bert', 'openai-gpt', 'gpt2', 'transfo-xl', 'xlnet', \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m                          \"'xlm', 'roberta', 'camembert', 'ctrl'\".format(pretrained_model_name_or_path))\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: Unrecognized model identifier in skt/ko-gpt-trinity-1.2B-v0.5. Should contains one of 'bert', 'openai-gpt', 'gpt2', 'transfo-xl', 'xlnet', 'xlm', 'roberta', 'camembert', 'ctrl'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import sagemaker\r\n",
    "import boto3\r\n",
    "from sagemaker.huggingface import HuggingFace\r\n",
    "\r\n",
    "# gets role for executing training job\r\n",
    "iam_client = boto3.client('iam')\r\n",
    "role = iam_client.get_role(RoleName='{IAM_ROLE_WITH_SAGEMAKER_PERMISSIONS}')['Role']['Arn']\r\n",
    "hyperparameters = {\r\n",
    "\t'model_name_or_path':'skt/ko-gpt-trinity-1.2B-v0.5',\r\n",
    "\t'output_dir':'/opt/ml/model'\r\n",
    "\t# add your remaining hyperparameters\r\n",
    "\t# more info here https://github.com/huggingface/transformers/tree/v4.6.1/examples/pytorch/question-answering\r\n",
    "}\r\n",
    "\r\n",
    "# git configuration to download our fine-tuning script\r\n",
    "git_config = {'repo': 'https://github.com/huggingface/transformers.git','branch': 'v4.6.1'}\r\n",
    "\r\n",
    "# creates Hugging Face estimator\r\n",
    "huggingface_estimator = HuggingFace(\r\n",
    "\tentry_point='run_qa.py',\r\n",
    "\tsource_dir='./examples/pytorch/question-answering',\r\n",
    "\tinstance_type='ml.p3.2xlarge',\r\n",
    "\tinstance_count=1,\r\n",
    "\trole=role,\r\n",
    "\tgit_config=git_config,\r\n",
    "\ttransformers_version='4.6.1',\r\n",
    "\tpytorch_version='1.7.1',\r\n",
    "\tpy_version='py36',\r\n",
    "\thyperparameters = hyperparameters\r\n",
    ")\r\n",
    "\r\n",
    "# starting the train job\r\n",
    "huggingface_estimator.fit()"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sagemaker'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp/ipykernel_10400/3734294516.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0msagemaker\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mboto3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msagemaker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhuggingface\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHuggingFace\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# gets role for executing training job\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sagemaker'"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('exam_cv2': conda)"
  },
  "interpreter": {
   "hash": "19a2027c367e4a8fbf50703f7b521df71edff403eb9eba2200ef5f1febf03a5b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}